{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/lggram/anaconda3/lib/python3.11/site-packages (25.1)\n",
      "Collecting pip\n",
      "  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 25.1\n",
      "    Uninstalling pip-25.1:\n",
      "      Successfully uninstalled pip-25.1\n",
      "Successfully installed pip-25.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: opencv-python in /home/lggram/anaconda3/lib/python3.11/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: scikit-learn in /home/lggram/anaconda3/lib/python3.11/site-packages (1.2.2)\n",
      "Requirement already satisfied: matplotlib in /home/lggram/anaconda3/lib/python3.11/site-packages (3.8.0)\n",
      "Requirement already satisfied: scipy==1.10.1 in /home/lggram/anaconda3/lib/python3.11/site-packages (1.10.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /home/lggram/anaconda3/lib/python3.11/site-packages (from scipy==1.10.1) (1.26.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/lggram/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/lggram/anaconda3/lib/python3.11/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/lggram/anaconda3/lib/python3.11/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/lggram/anaconda3/lib/python3.11/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/lggram/anaconda3/lib/python3.11/site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/lggram/anaconda3/lib/python3.11/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/lggram/anaconda3/lib/python3.11/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/lggram/anaconda3/lib/python3.11/site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/lggram/anaconda3/lib/python3.11/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/lggram/anaconda3/lib/python3.11/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/lggram/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install opencv-python scikit-learn matplotlib scipy==1.10.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute SIFT features for training images\n",
      "Build visual dictionary\n",
      "Compute Bag of Words features for training images\n",
      "Compute Bag of Words features for test images\n",
      "Predict with kNN\n",
      "Compute SIFT features for training images\n",
      "Build visual dictionary\n",
      "Compute Bag of Words features for training images\n",
      "Compute Bag of Words features for test images\n",
      "Predict with SVM\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from scipy import stats\n",
    "from pathlib import Path, PureWindowsPath\n",
    "import random\n",
    "\n",
    "\n",
    "def extract_dataset_info(data_path):\n",
    "    label_classes = set()\n",
    "    label_train_list = []\n",
    "    img_train_list = []\n",
    "    label_test_list = []\n",
    "    img_test_list = []\n",
    "    data_dir = Path(data_path)\n",
    "    for entry in open(data_dir / \"train.txt\"):\n",
    "        label, img_path = entry.strip().split()\n",
    "        label_classes.add(label)\n",
    "        img_train_list.append(str(data_dir / img_path))\n",
    "        label_train_list.append(label)\n",
    "    for entry in open(data_dir / \"test.txt\"):\n",
    "        label, img_path = entry.strip().split()\n",
    "        label_classes.add(label)\n",
    "        img_test_list.append(str(data_dir / img_path))\n",
    "        label_test_list.append(label)\n",
    "    label_classes = sorted(list(label_classes))\n",
    "    label_train_list = np.array(\n",
    "        [label_classes.index(label) for label in label_train_list]\n",
    "    )\n",
    "    label_test_list = np.array(\n",
    "        [label_classes.index(label) for label in label_test_list]\n",
    "    )\n",
    "    return label_classes, label_train_list, img_train_list, label_test_list, img_test_list\n",
    "\n",
    "\n",
    "def compute_dsift(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    size = 16\n",
    "    step = 8\n",
    "    sift = cv2.SIFT_create()\n",
    "    kp = [\n",
    "        cv2.KeyPoint(x, y, size)\n",
    "        for y in range(0, img.shape[0], step)\n",
    "        for x in range(0, img.shape[1], step)\n",
    "    ]\n",
    "    kp, dense_feature = sift.compute(img, kp)\n",
    "    return dense_feature\n",
    "\n",
    "\n",
    "def predict_knn(feature_train, label_train, feature_test, k):\n",
    "    model = NearestNeighbors(n_neighbors=k)\n",
    "    model.fit(feature_train)\n",
    "    neighbors = model.kneighbors(feature_test, return_distance=False)\n",
    "    label_test_pred = []\n",
    "    for idxs in neighbors:\n",
    "        neighbor_labels = label_train[idxs]\n",
    "        label = stats.mode(neighbor_labels, keepdims=False)[0]\n",
    "        label_test_pred.append(label)\n",
    "    return label_test_pred\n",
    "\n",
    "\n",
    "def build_visual_dictionary(dense_feature_list, dic_size):\n",
    "    vocab = KMeans(n_clusters=dic_size, n_init=\"auto\", random_state=11).fit(\n",
    "        dense_feature_list\n",
    "    )\n",
    "    return vocab\n",
    "\n",
    "\n",
    "def compute_bow(feature, vocab):\n",
    "    if feature is None or len(feature) == 0:\n",
    "        return np.zeros((vocab.n_clusters,), dtype=np.float32)\n",
    "\n",
    "    cluster_indices = vocab.predict(feature)\n",
    "    bow_feature, _ = np.histogram(cluster_indices, bins=np.arange(vocab.n_clusters + 1))\n",
    "    norm = np.linalg.norm(bow_feature)\n",
    "    if norm > 0:\n",
    "        bow_feature = bow_feature / norm\n",
    "\n",
    "    return bow_feature\n",
    "\n",
    "\n",
    "def classify_knn_bow(label_classes, label_train_list, img_train_list, label_test_list, img_test_list):\n",
    "    print(\"Compute SIFT features for training images\")\n",
    "    dense_feature_list_train = [\n",
    "        compute_dsift(cv2.imread(img)) for img in img_train_list\n",
    "    ]\n",
    "    all_train_features = np.vstack(\n",
    "        [f for f in dense_feature_list_train if f is not None]\n",
    "    )\n",
    "    print(\"Build visual dictionary\")\n",
    "    vocab = build_visual_dictionary(all_train_features, 400)\n",
    "    print(\"Compute Bag of Words features for training images\")\n",
    "    bow_train = np.vstack([compute_bow(f, vocab) for f in dense_feature_list_train])\n",
    "    print(\"Compute Bag of Words features for test images\")\n",
    "    dense_feature_list_test = [compute_dsift(cv2.imread(img)) for img in img_test_list]\n",
    "    bow_test = np.vstack([compute_bow(f, vocab) for f in dense_feature_list_test])\n",
    "    print(\"Predict with kNN\")\n",
    "    label_test_pred = predict_knn(bow_train, label_train_list, bow_test, 10)\n",
    "    confusion = np.zeros((len(label_classes), len(label_classes)), dtype=np.int32)\n",
    "    for i in range(len(label_test_pred)):\n",
    "        confusion[label_test_list[i], label_test_pred[i]] += 1\n",
    "    accuracy = np.trace(confusion) / np.sum(confusion)\n",
    "    visualize_confusion_matrix(confusion, accuracy, label_classes, method_name=\"bow_knn\")\n",
    "    return confusion, accuracy\n",
    "\n",
    "\n",
    "def predict_svm(feature_train, label_train, feature_test):\n",
    "    classes = np.unique(label_train)\n",
    "    n_classes = len(classes)\n",
    "    n_test = feature_test.shape[0]\n",
    "    scores = np.zeros((n_test, n_classes))\n",
    "    for idx, cls in enumerate(classes):\n",
    "        # 1 vs all: 1 for current class, 0 for others\n",
    "        binary_labels = (label_train == cls).astype(int)\n",
    "        model = SVC(C=2, kernel=\"linear\", probability=False, random_state=0)\n",
    "        model.fit(feature_train, binary_labels)\n",
    "        scores[:, idx] = model.decision_function(feature_test)\n",
    "    label_test_pred = np.argmax(scores, axis=1)\n",
    "    return label_test_pred\n",
    "\n",
    "\n",
    "def classify_svm_bow(label_classes, label_train_list, img_train_list, label_test_list, img_test_list):\n",
    "    print(\"Compute SIFT features for training images\")\n",
    "    dense_feature_list_train = [\n",
    "        compute_dsift(cv2.imread(img)) for img in img_train_list\n",
    "    ]\n",
    "    all_train_features = np.vstack(\n",
    "        [f for f in dense_feature_list_train if f is not None]\n",
    "    )\n",
    "    print(\"Build visual dictionary\")\n",
    "    vocab = build_visual_dictionary(all_train_features, 600)\n",
    "    print(\"Compute Bag of Words features for training images\")\n",
    "    bow_train = np.vstack([compute_bow(f, vocab) for f in dense_feature_list_train])\n",
    "    print(\"Compute Bag of Words features for test images\")\n",
    "    dense_feature_list_test = [compute_dsift(cv2.imread(img)) for img in img_test_list]\n",
    "    bow_test = np.vstack([compute_bow(f, vocab) for f in dense_feature_list_test])\n",
    "    print(\"Predict with SVM\")\n",
    "    label_test_pred = predict_svm(bow_train, label_train_list, bow_test)\n",
    "    confusion = np.zeros((len(label_classes), len(label_classes)), dtype=np.int32)\n",
    "    for i in range(len(label_test_pred)):\n",
    "        confusion[label_test_list[i], label_test_pred[i]] += 1\n",
    "    accuracy = np.trace(confusion) / np.sum(confusion)\n",
    "    visualize_confusion_matrix(confusion, accuracy, label_classes, method_name=\"bow_svm\")\n",
    "    return confusion, accuracy\n",
    "\n",
    "\n",
    "def visualize_confusion_matrix(confusion, accuracy, label_classes,  method_name, out_dir=\"outputs\"):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    plt.title(\"accuracy = {:.3f}\".format(accuracy))\n",
    "    plt.imshow(confusion)\n",
    "    ax, fig = plt.gca(), plt.gcf()\n",
    "    plt.xticks(np.arange(len(label_classes)), label_classes)\n",
    "    plt.yticks(np.arange(len(label_classes)), label_classes)\n",
    "    # set horizontal alignment mode (left, right or center) and rotation mode(anchor or default)\n",
    "    plt.setp(ax.get_xticklabels(), rotation=-30, ha=\"center\", rotation_mode=\"default\")\n",
    "    # avoid top and bottom part of heatmap been cut\n",
    "    ax.set_xticks(np.arange(len(label_classes) + 1) - .5, minor=True)\n",
    "    ax.set_yticks(np.arange(len(label_classes) + 1) - .5, minor=True)\n",
    "    ax.tick_params(which=\"minor\", bottom=False, left=False)\n",
    "    fig.tight_layout()\n",
    "    fname = os.path.join(out_dir, f\"{method_name}_confusion_acc.png\")\n",
    "    plt.savefig(fname, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    label_classes, label_train_list, img_train_list, label_test_list, img_test_list = extract_dataset_info(\"./scene_classification_data\")\n",
    "\n",
    "    classify_knn_bow(label_classes, label_train_list, img_train_list, label_test_list, img_test_list)\n",
    "    \n",
    "    classify_svm_bow(label_classes, label_train_list, img_train_list, label_test_list, img_test_list)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
